{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76720bef-9446-4e7b-9a50-b559fd7bfb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing class 1/6: Lindsay_Lohan (Originals)\n",
      "Processing class 2/6: Tom_Cruise (Originals)\n",
      "Processing class 3/6: Leonardo_DiCaprio (Originals)\n",
      "Processing class 4/6: Daniel_Radcliffe (Originals)\n",
      "Processing class 5/6: Orlando_Bloom (Originals)\n",
      "Processing class 6/6: Miley_Cyrus (Originals)\n",
      "Original images split: Train=1333, Test=334\n",
      "Augmenting Train set...\n",
      "Augmenting Test set...\n",
      "Class Miley_Cyrus:\n",
      "  - Original images: 524\n",
      "  - Augmented images: 1310\n",
      "  - Total: 1572\n",
      "Class Daniel_Radcliffe:\n",
      "  - Original images: 528\n",
      "  - Augmented images: 1320\n",
      "  - Total: 1584\n",
      "Class Tom_Cruise:\n",
      "  - Original images: 414\n",
      "  - Augmented images: 1034\n",
      "  - Total: 1241\n",
      "Class Lindsay_Lohan:\n",
      "  - Original images: 746\n",
      "  - Augmented images: 1865\n",
      "  - Total: 2238\n",
      "Class Leonardo_DiCaprio:\n",
      "  - Original images: 422\n",
      "  - Augmented images: 1055\n",
      "  - Total: 1266\n",
      "Class Orlando_Bloom:\n",
      "  - Original images: 700\n",
      "  - Augmented images: 1750\n",
      "  - Total: 2100\n",
      "\n",
      "Summary:\n",
      "Total original images attempted: 1738\n",
      "Original images successfully processed: 1667\n",
      "Images skipped: 71\n",
      "Final dataset size (with augmentations): 10001\n",
      "Class distribution:\n",
      "  - Miley_Cyrus: 1572 images (Original: 524, Augmented: 1310)\n",
      "  - Daniel_Radcliffe: 1584 images (Original: 528, Augmented: 1320)\n",
      "  - Tom_Cruise: 1241 images (Original: 414, Augmented: 1034)\n",
      "  - Lindsay_Lohan: 2238 images (Original: 746, Augmented: 1865)\n",
      "  - Leonardo_DiCaprio: 1266 images (Original: 422, Augmented: 1055)\n",
      "  - Orlando_Bloom: 2100 images (Original: 700, Augmented: 1750)\n",
      "Skipped images (first 5):\n",
      "  1. /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/405.jpg: No face detected (Shape: (256, 256))\n",
      "  2. /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/398.jpg: No face detected (Shape: (256, 256))\n",
      "  3. /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/472.jpg: No face detected (Shape: (256, 256))\n",
      "  4. /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/311.jpg: No face detected (Shape: (256, 256))\n",
      "  5. /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/306.jpg: No face detected (Shape: (256, 256))\n",
      "Dataset loading time: 27.64 seconds\n",
      "Total images (with augmentation): 10001\n",
      "Loaded pre-downloaded FaceNet weights\n",
      "Starting embedding computation for 10001 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|███████████████████| 313/313 [09:17<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding norms: mean=1.00, std=0.00\n",
      "Embedding time: 558.24 seconds\n",
      "Standardized embeddings\n",
      "Encoded labels\n",
      "PCA reduced dimensions to: 30\n",
      "Explained variance ratio: 0.8454\n",
      "PCA time: 0.06 seconds\n",
      "Training samples: 8000, Test samples: 2001\n",
      "Data split time: 0.00 seconds\n",
      "Memory usage before training: 80.1%\n",
      "Starting SVM training...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best SVM parameters: {'C': 0.001, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVM Cross-validation accuracy: 0.86 ± 0.01\n",
      "SVM Test accuracy: 0.87\n",
      "SVM Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " Daniel_Radcliffe       0.80      0.86      0.83       317\n",
      "Leonardo_DiCaprio       0.87      0.86      0.87       253\n",
      "    Lindsay_Lohan       0.87      0.87      0.87       448\n",
      "      Miley_Cyrus       0.89      0.84      0.86       315\n",
      "    Orlando_Bloom       0.96      0.88      0.91       420\n",
      "       Tom_Cruise       0.80      0.90      0.85       248\n",
      "\n",
      "         accuracy                           0.87      2001\n",
      "        macro avg       0.86      0.87      0.86      2001\n",
      "     weighted avg       0.87      0.87      0.87      2001\n",
      "\n",
      "SVM EER for Daniel_Radcliffe: 0.0808\n",
      "SVM EER for Leonardo_DiCaprio: 0.0761\n",
      "SVM EER for Lindsay_Lohan: 0.0753\n",
      "SVM EER for Miley_Cyrus: 0.0676\n",
      "SVM EER for Orlando_Bloom: 0.0664\n",
      "SVM EER for Tom_Cruise: 0.0536\n",
      "SVM Average EER: 0.0700\n",
      "SVM training and evaluation time: 49.00 seconds\n",
      "Starting MLP training...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/sklearn/model_selection/_search.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.array(param_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MLP parameters: {'alpha': 0.01, 'hidden_layer_sizes': (100, 50), 'learning_rate_init': 0.01}\n",
      "MLP Cross-validation accuracy: 0.85 ± 0.01\n",
      "MLP Test accuracy: 0.85\n",
      "MLP Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " Daniel_Radcliffe       0.83      0.82      0.82       317\n",
      "Leonardo_DiCaprio       0.85      0.83      0.84       253\n",
      "    Lindsay_Lohan       0.88      0.83      0.86       448\n",
      "      Miley_Cyrus       0.81      0.83      0.82       315\n",
      "    Orlando_Bloom       0.86      0.90      0.88       420\n",
      "       Tom_Cruise       0.84      0.86      0.85       248\n",
      "\n",
      "         accuracy                           0.85      2001\n",
      "        macro avg       0.84      0.84      0.84      2001\n",
      "     weighted avg       0.85      0.85      0.85      2001\n",
      "\n",
      "MLP EER for Daniel_Radcliffe: 0.0950\n",
      "MLP EER for Leonardo_DiCaprio: 0.0967\n",
      "MLP EER for Lindsay_Lohan: 0.0959\n",
      "MLP EER for Miley_Cyrus: 0.0943\n",
      "MLP EER for Orlando_Bloom: 0.0677\n",
      "MLP EER for Tom_Cruise: 0.0696\n",
      "MLP Average EER: 0.0865\n",
      "MLP training and evaluation time: 17.69 seconds\n",
      "Starting Random Forest training...\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Best Random Forest parameters: {'n_estimators': 100}\n",
      "Random Forest Cross-validation accuracy: 0.85 ± 0.01\n",
      "Random Forest Test accuracy: 0.84\n",
      "Random Forest Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      " Daniel_Radcliffe       0.78      0.83      0.80       317\n",
      "Leonardo_DiCaprio       0.88      0.82      0.85       253\n",
      "    Lindsay_Lohan       0.83      0.85      0.84       448\n",
      "      Miley_Cyrus       0.87      0.82      0.84       315\n",
      "    Orlando_Bloom       0.89      0.87      0.88       420\n",
      "       Tom_Cruise       0.81      0.84      0.82       248\n",
      "\n",
      "         accuracy                           0.84      2001\n",
      "        macro avg       0.84      0.84      0.84      2001\n",
      "     weighted avg       0.84      0.84      0.84      2001\n",
      "\n",
      "Random Forest EER for Daniel_Radcliffe: 0.0986\n",
      "Random Forest EER for Leonardo_DiCaprio: 0.0732\n",
      "Random Forest EER for Lindsay_Lohan: 0.0979\n",
      "Random Forest EER for Miley_Cyrus: 0.0836\n",
      "Random Forest EER for Orlando_Bloom: 0.0645\n",
      "Random Forest EER for Tom_Cruise: 0.0844\n",
      "Random Forest Average EER: 0.0837\n",
      "Random Forest training and evaluation time: 11.32 seconds\n",
      "Models saved to /Users/anantasingh/Desktop/advcslocal2/output/face_models_full.pkl\n",
      "Intra-class similarity: mean=0.2867, std=0.2755\n",
      "Inter-class similarity: mean=-0.0540, std=0.1871\n"
     ]
    }
   ],
   "source": [
    "# Augmentation\n",
    "# Facial Recognition System\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import time\n",
    "import gc\n",
    "import psutil\n",
    "from collections import defaultdict\n",
    "import hashlib\n",
    "import concurrent.futures\n",
    "import imgaug.augmenters as iaa\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Augmentation pipeline\n",
    "def get_augmentation_pipeline():\n",
    "    return iaa.Sequential([\n",
    "        iaa.Sometimes(0.7, iaa.Affine(\n",
    "            scale={\"x\": (0.7, 1.3), \"y\": (0.7, 1.3)},\n",
    "            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "            rotate=(-45, 45),\n",
    "            shear=(-15, 15),\n",
    "            order=[0, 1],\n",
    "            mode='reflect'\n",
    "        )),\n",
    "        iaa.Sometimes(0.7, iaa.OneOf([\n",
    "            iaa.Multiply((0.5, 1.5)),\n",
    "            iaa.LinearContrast((0.5, 1.5)),\n",
    "            iaa.AddToHueAndSaturation((-30, 30))\n",
    "        ])),\n",
    "        iaa.Sometimes(0.5, iaa.AdditiveGaussianNoise(scale=(0, 0.1*255))),\n",
    "        iaa.Sometimes(0.4, iaa.GaussianBlur(sigma=(0, 1.5))),\n",
    "        iaa.Sometimes(0.3, iaa.PerspectiveTransform(scale=(0.05, 0.15))),\n",
    "        iaa.Sometimes(0.4, iaa.Add((-50, 50))),\n",
    "        iaa.Sometimes(0.5, iaa.CoarseDropout((0.0, 0.05), size_percent=(0.02, 0.25))),\n",
    "    ])\n",
    "\n",
    "# FACELOADING class\n",
    "class FACELOADING:\n",
    "    def __init__(self, directory, target_size=(160, 160), batch_size=32, max_workers=4):\n",
    "        self.directory = directory\n",
    "        self.target_size = target_size\n",
    "        self.batch_size = batch_size\n",
    "        self.max_workers = max_workers\n",
    "        self.detector = None\n",
    "        self.skipped_images = []\n",
    "        self.processed_images = 0\n",
    "        self.total_images = 0\n",
    "        self.image_hashes = defaultdict(list)\n",
    "        self.augmentation_pipeline = get_augmentation_pipeline()\n",
    "        self.output_dir = \"/Users/anantasingh/Desktop/advcslocal2/output/processed_images\"\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "    def get_detector(self):\n",
    "        if self.detector is None:\n",
    "            self.detector = MTCNN(\n",
    "                thresholds=[0.6, 0.7, 0.7],\n",
    "                min_face_size=20,\n",
    "                device=torch.device('cpu'),\n",
    "                post_process=False,\n",
    "                select_largest=True\n",
    "            )\n",
    "        return self.detector\n",
    "\n",
    "    def compute_image_hash(self, img):\n",
    "        small_img = cv2.resize(img, (32, 32))\n",
    "        return hashlib.md5(small_img.tobytes()).hexdigest()\n",
    "\n",
    "    def extract_face(self, filename):\n",
    "        try:\n",
    "            img = cv2.imread(filename)\n",
    "            if img is None:\n",
    "                self.skipped_images.append((filename, \"Failed to load image\", (0, 0)))\n",
    "                return None\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            height, width = img.shape[:2]\n",
    "            detector = self.get_detector()\n",
    "            boxes, probs, landmarks = detector.detect(img, landmarks=True)\n",
    "            if boxes is None or len(boxes) == 0:\n",
    "                self.skipped_images.append((filename, \"No face detected\", (height, width)))\n",
    "                return None\n",
    "            x1, y1, x2, y2 = map(int, boxes[0])\n",
    "            x1, x2 = max(0, x1), min(width, x2)\n",
    "            y1, y2 = max(0, y1), min(height, y2)\n",
    "            if x1 >= x2 or y1 >= y2:\n",
    "                self.skipped_images.append((filename, \"Invalid bounding box\", (height, width)))\n",
    "                return None\n",
    "            face = img[y1:y2, x1:x2]\n",
    "            if face.size == 0 or face.shape[0] == 0 or face.shape[1] == 0:\n",
    "                self.skipped_images.append((filename, \"Empty face after cropping\", (height, width)))\n",
    "                return None\n",
    "            face = cv2.resize(face, self.target_size)\n",
    "            img_hash = self.compute_image_hash(face)\n",
    "            self.image_hashes[img_hash].append(filename)\n",
    "            self.processed_images += 1\n",
    "            return face\n",
    "        except Exception as e:\n",
    "            self.skipped_images.append((filename, f\"Error: {str(e)}\", (0, 0)))\n",
    "            return None\n",
    "\n",
    "    def augment_face(self, face, num_augmentations=5):\n",
    "        augmented_faces = []\n",
    "        for _ in range(num_augmentations):\n",
    "            augmented = self.augmentation_pipeline(image=face)\n",
    "            if augmented.mean() > 10:\n",
    "                augmented_faces.append(augmented)\n",
    "        return augmented_faces\n",
    "\n",
    "    def process_image_batch(self, image_paths, class_name, augment=True, num_augmentations=5):\n",
    "        results = []\n",
    "        class_output_dir = os.path.join(self.output_dir, class_name)\n",
    "        original_dir = os.path.join(class_output_dir, \"original\")\n",
    "        augmented_dir = os.path.join(class_output_dir, \"augmented\")\n",
    "        os.makedirs(original_dir, exist_ok=True)\n",
    "        os.makedirs(augmented_dir, exist_ok=True)\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            future_to_path = {executor.submit(self.extract_face, path): path for path in image_paths}\n",
    "            for future in concurrent.futures.as_completed(future_to_path):\n",
    "                path = future_to_path[future]\n",
    "                filename = os.path.basename(path)\n",
    "                face = future.result()\n",
    "                if face is not None:\n",
    "                    original_path = os.path.join(original_dir, filename)\n",
    "                    cv2.imwrite(original_path, cv2.cvtColor(face, cv2.COLOR_RGB2BGR))\n",
    "                    results.append((face, class_name, \"original\"))\n",
    "                    if augment:\n",
    "                        augmented_faces = self.augment_face(face, num_augmentations)\n",
    "                        for i, aug_face in enumerate(augmented_faces):\n",
    "                            aug_filename = f\"{os.path.splitext(filename)[0]}_aug{i+1}{os.path.splitext(filename)[1]}\"\n",
    "                            aug_path = os.path.join(augmented_dir, aug_filename)\n",
    "                            cv2.imwrite(aug_path, cv2.cvtColor(aug_face, cv2.COLOR_RGB2BGR))\n",
    "                            results.append((aug_face, class_name, \"augmented\"))\n",
    "        return results\n",
    "\n",
    "    def load_faces(self, dir, class_name, augment=True, num_augmentations=5):\n",
    "        image_paths = []\n",
    "        for filename in os.listdir(dir):\n",
    "            if not (filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg')):\n",
    "                continue\n",
    "            self.total_images += 1\n",
    "            path = os.path.join(dir, filename)\n",
    "            image_paths.append(path)\n",
    "        batch_size = self.batch_size\n",
    "        face_data = []\n",
    "        for i in range(0, len(image_paths), batch_size):\n",
    "            batch_paths = image_paths[i:i+batch_size]\n",
    "            batch_results = self.process_image_batch(batch_paths, class_name, augment, num_augmentations)\n",
    "            face_data.extend(batch_results)\n",
    "        faces = [item[0] for item in face_data]\n",
    "        self._save_sample_images(face_data, class_name)\n",
    "        return np.asarray(faces)\n",
    "\n",
    "    def _save_sample_images(self, face_data, class_name):\n",
    "        class_output_dir = os.path.join(self.output_dir, class_name)\n",
    "        os.makedirs(class_output_dir, exist_ok=True)\n",
    "        originals = [face for face, _, type_ in face_data if type_ == \"original\"]\n",
    "        augmented = [face for face, _, type_ in face_data if type_ == \"augmented\"]\n",
    "        if not originals or not augmented:\n",
    "            return\n",
    "        n_samples = min(3, len(originals))\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        for i in range(n_samples):\n",
    "            plt.subplot(n_samples, 3, i*3 + 1)\n",
    "            plt.imshow(originals[i])\n",
    "            plt.title(f\"Original {i+1}\")\n",
    "            plt.axis('off')\n",
    "            aug_indices = [j for j in range(len(augmented)) if j % len(originals) == i]\n",
    "            if len(aug_indices) >= 2:\n",
    "                plt.subplot(n_samples, 3, i*3 + 2)\n",
    "                plt.imshow(augmented[aug_indices[0]])\n",
    "                plt.title(f\"Augmented {i+1}.1\")\n",
    "                plt.axis('off')\n",
    "                plt.subplot(n_samples, 3, i*3 + 3)\n",
    "                plt.imshow(augmented[aug_indices[1]])\n",
    "                plt.title(f\"Augmented {i+1}.2\")\n",
    "                plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{class_output_dir}/comparison.png')\n",
    "        plt.close()\n",
    "\n",
    "    def load_classes(self, augment=True, num_augmentations=5):\n",
    "        X_original, Y_original = [], []\n",
    "        class_counts = {}\n",
    "        original_counts = {}\n",
    "        augmented_counts = {}\n",
    "        total_classes = sum(1 for item in os.listdir(self.directory) if os.path.isdir(os.path.join(self.directory, item)))\n",
    "        face_data_per_class = defaultdict(list)\n",
    "        \n",
    "        #Original images without augmentation\n",
    "        for i, sub_dir in enumerate(os.listdir(self.directory)):\n",
    "            path = os.path.join(self.directory, sub_dir)\n",
    "            if os.path.isdir(path):\n",
    "                print(f\"Processing class {i+1}/{total_classes}: {sub_dir} (Originals)\")\n",
    "                faces = self.load_faces(path, sub_dir, augment=False)\n",
    "                if len(faces) == 0:\n",
    "                    print(f\"Warning: No faces found in class {sub_dir}\")\n",
    "                    continue\n",
    "                class_output_dir = os.path.join(self.output_dir, sub_dir)\n",
    "                original_dir = os.path.join(class_output_dir, \"original\")\n",
    "                os.makedirs(original_dir, exist_ok=True)\n",
    "                for j, face in enumerate(faces):\n",
    "                    filename = f\"original_{j+1}.jpg\"\n",
    "                    original_path = os.path.join(original_dir, filename)\n",
    "                    cv2.imwrite(original_path, cv2.cvtColor(face, cv2.COLOR_RGB2BGR))\n",
    "                    face_data_per_class[sub_dir].append((face, sub_dir, \"original\"))\n",
    "                X_original.extend(faces)\n",
    "                Y_original.extend([sub_dir] * len(faces))\n",
    "        \n",
    "        #Split original images into train and test sets\n",
    "        X_train_orig, X_test_orig, Y_train_orig, Y_test_orig = train_test_split(\n",
    "            X_original, Y_original, test_size=0.2, random_state=42, stratify=Y_original\n",
    "        )\n",
    "        print(f\"Original images split: Train={len(X_train_orig)}, Test={len(X_test_orig)}\")\n",
    "        \n",
    "        # Check for hash overlap between train and test\n",
    "        train_hashes = [self.compute_image_hash(face) for face in X_train_orig]\n",
    "        test_hashes = [self.compute_image_hash(face) for face in X_test_orig]\n",
    "        common_hashes = set(train_hashes).intersection(set(test_hashes))\n",
    "        if common_hashes:\n",
    "            print(f\"Warning: Found {len(common_hashes)} hashes in both train and test sets!\")\n",
    "            with open(\"/Users/anantasingh/Desktop/advcslocal2/output/common_hashes.txt\", 'w') as f:\n",
    "                f.write(str(common_hashes))\n",
    "        \n",
    "        #Augment train and test sets separately and save augmented images\n",
    "        X, Y = [], []\n",
    "        aug_counter = defaultdict(int)  # To track augmented image indices per class\n",
    "        for split_name, faces, labels in [(\"Train\", X_train_orig, Y_train_orig), (\"Test\", X_test_orig, Y_test_orig)]:\n",
    "            print(f\"Augmenting {split_name} set...\")\n",
    "            for face, label in zip(faces, labels):\n",
    "                X.append(face)\n",
    "                Y.append(label)\n",
    "                face_data_per_class[label].append((face, label, \"original\"))  # Ensure originals are in face_data\n",
    "                if augment:\n",
    "                    augmented_faces = self.augment_face(face, num_augmentations)\n",
    "                    class_output_dir = os.path.join(self.output_dir, label)\n",
    "                    augmented_dir = os.path.join(class_output_dir, \"augmented\")\n",
    "                    os.makedirs(augmented_dir, exist_ok=True)\n",
    "                    for i, aug_face in enumerate(augmented_faces):\n",
    "                        aug_counter[label] += 1\n",
    "                        aug_filename = f\"augmented_{aug_counter[label]}.jpg\"\n",
    "                        aug_path = os.path.join(augmented_dir, aug_filename)\n",
    "                        cv2.imwrite(aug_path, cv2.cvtColor(aug_face, cv2.COLOR_RGB2BGR))\n",
    "                        X.append(aug_face)\n",
    "                        Y.append(label)\n",
    "                        face_data_per_class[label].append((aug_face, label, \"augmented\"))\n",
    "        \n",
    "        # Save sample images for each class\n",
    "        for class_name, face_data in face_data_per_class.items():\n",
    "            self._save_sample_images(face_data, class_name)\n",
    "        \n",
    "        # Compute counts and summaries\n",
    "        for sub_dir in set(Y):\n",
    "            class_counts[sub_dir] = sum(1 for label in Y if label == sub_dir)\n",
    "            original_dir = os.path.join(self.output_dir, sub_dir, \"original\")\n",
    "            augmented_dir = os.path.join(self.output_dir, sub_dir, \"augmented\")\n",
    "            original_count = len([f for f in os.listdir(original_dir) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "            augmented_count = len([f for f in os.listdir(augmented_dir) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "            original_counts[sub_dir] = original_count\n",
    "            augmented_counts[sub_dir] = augmented_count\n",
    "            print(f\"Class {sub_dir}:\")\n",
    "            print(f\"  - Original images: {original_count}\")\n",
    "            print(f\"  - Augmented images: {augmented_count}\")\n",
    "            print(f\"  - Total: {class_counts[sub_dir]}\")\n",
    "        \n",
    "        print(f\"\\nSummary:\")\n",
    "        print(f\"Total original images attempted: {self.total_images}\")\n",
    "        print(f\"Original images successfully processed: {self.processed_images}\")\n",
    "        print(f\"Images skipped: {len(self.skipped_images)}\")\n",
    "        print(f\"Final dataset size (with augmentations): {len(X)}\")\n",
    "        print(f\"Class distribution:\")\n",
    "        for cls, count in class_counts.items():\n",
    "            print(f\"  - {cls}: {count} images (Original: {original_counts[cls]}, Augmented: {augmented_counts[cls]})\")\n",
    "        \n",
    "        # Check for duplicate hashes\n",
    "        duplicate_hashes = {h: paths for h, paths in self.image_hashes.items() if len(paths) > 1}\n",
    "        if duplicate_hashes:\n",
    "            print(\"Warning: Detected duplicate image hashes (potential data leakage):\")\n",
    "            with open(\"/Users/anantasingh/Desktop/advcslocal2/output/duplicate_hashes.txt\", 'w') as f:\n",
    "                for h, paths in list(duplicate_hashes.items())[:5]:\n",
    "                    print(f\"  Hash {h}: {paths}\")\n",
    "                    f.write(f\"Hash {h}: {paths}\\n\")\n",
    "        if self.skipped_images:\n",
    "            print(\"Skipped images (first 5):\")\n",
    "            for i, (path, reason, shape) in enumerate(self.skipped_images[:5]):\n",
    "                print(f\"  {i+1}. {path}: {reason} (Shape: {shape})\")\n",
    "            with open(\"/Users/anantasingh/Desktop/advcslocal2/output/skipped_images.txt\", 'w') as f:\n",
    "                for path, reason, shape in self.skipped_images:\n",
    "                    f.write(f\"{path}: {reason} (Shape: {shape})\\n\")\n",
    "        with open(\"/Users/anantasingh/Desktop/advcslocal2/output/dataset_summary.txt\", 'w') as f:\n",
    "            f.write(f\"Total original images attempted: {self.total_images}\\n\")\n",
    "            f.write(f\"Original images successfully processed: {self.processed_images}\\n\")\n",
    "            f.write(f\"Images skipped: {len(self.skipped_images)}\\n\")\n",
    "            f.write(f\"Final dataset size (with augmentations): {len(X)}\\n\")\n",
    "            f.write(\"Class distribution:\\n\")\n",
    "            for cls, count in class_counts.items():\n",
    "                f.write(f\"  - {cls}: {count} images (Original: {original_counts[cls]}, Augmented: {augmented_counts[cls]})\\n\")\n",
    "        return np.asarray(X), np.asarray(Y)\n",
    "\n",
    "    def plot_images(self, X, Y, n=10):\n",
    "        plt.figure(figsize=(15, 3))\n",
    "        for i in range(min(n, len(X))):\n",
    "            plt.subplot(1, n, i+1)\n",
    "            plt.imshow(X[i])\n",
    "            plt.title(Y[i])\n",
    "            plt.axis('off')\n",
    "        plt.savefig(\"/Users/anantasingh/Desktop/advcslocal2/output/sample_images.png\")\n",
    "        plt.close()\n",
    "\n",
    "# embedding computation\n",
    "def get_embedding_batch(faces, embedder, batch_size=32):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(faces), batch_size), desc=\"Computing embeddings\"):\n",
    "        batch = faces[i:i+batch_size]\n",
    "        batch = np.array(batch).astype('float32') / 255.0\n",
    "        batch_tensor = torch.from_numpy(batch).permute(0, 3, 1, 2).to(torch.device('cpu'))\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = embedder(batch_tensor).cpu().numpy()\n",
    "        batch_embeddings = batch_embeddings / np.linalg.norm(batch_embeddings, axis=1, keepdims=True)\n",
    "        embeddings.extend(batch_embeddings)\n",
    "        if i % (batch_size * 20) == 0 and i > 0:\n",
    "            np.save(\"/Users/anantasingh/Desktop/advcslocal2/output/temp_embeddings.npy\", np.array(embeddings))\n",
    "        del batch_tensor\n",
    "        torch.cuda.empty_cache()\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    dataset_path = \"/Users/anantasingh/Desktop/advcslocal2/celebrities\"\n",
    "    faceloading = FACELOADING(dataset_path, batch_size=32, max_workers=4)\n",
    "    X, Y = faceloading.load_classes(augment=True, num_augmentations=5)\n",
    "    faceloading.plot_images(X, Y, n=10)\n",
    "    print(f\"Dataset loading time: {time.time() - start_time:.2f} seconds\")\n",
    "    print(f\"Total images (with augmentation): {len(X)}\")\n",
    "    start_time = time.time()\n",
    "    device = torch.device('cpu')\n",
    "    embedder = InceptionResnetV1(pretrained='vggface2', classify=False).eval().to(device)\n",
    "    weights_path = \"/Users/anantasingh/Desktop/advcslocal2/vggface2_weights.pt\"\n",
    "    if os.path.exists(weights_path):\n",
    "        try:\n",
    "            state_dict = torch.load(weights_path, map_location=device)\n",
    "            state_dict = {k: v for k, v in state_dict.items() if not k.startswith('logits')}\n",
    "            embedder.load_state_dict(state_dict, strict=False)\n",
    "            print(\"Loaded pre-downloaded FaceNet weights\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error loading weights: {e}\")\n",
    "            print(\"Regenerating weights...\")\n",
    "            embedder = InceptionResnetV1(pretrained='vggface2', classify=False).eval().to(device)\n",
    "            torch.save(embedder.state_dict(), weights_path)\n",
    "    else:\n",
    "        print(\"Weights not found, downloading...\")\n",
    "        embedder = InceptionResnetV1(pretrained='vggface2', classify=False).eval().to(device)\n",
    "        torch.save(embedder.state_dict(), weights_path)\n",
    "    embedding_cache = \"/Users/anantasingh/Desktop/advcslocal2/output/faces_embeddings_full.npz\"\n",
    "    print(f\"Starting embedding computation for {len(X)} images...\")\n",
    "    EMBEDDED_X = get_embedding_batch(X, embedder, batch_size=32)\n",
    "    embedding_norms = np.linalg.norm(EMBEDDED_X, axis=1)\n",
    "    print(f\"Embedding norms: mean={np.mean(embedding_norms):.2f}, std={np.std(embedding_norms):.2f}\")\n",
    "    if np.any(embedding_norms < 0.1):\n",
    "        print(\"Warning: Some embeddings have low norms\")\n",
    "    np.savez_compressed(embedding_cache, EMBEDDED_X=EMBEDDED_X, Y=Y)\n",
    "    print(f\"Embedding time: {time.time() - start_time:.2f} seconds\")\n",
    "    del embedder\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    scaler = StandardScaler()\n",
    "    EMBEDDED_X = scaler.fit_transform(EMBEDDED_X)\n",
    "    print(\"Standardized embeddings\")\n",
    "    start_time = time.time()\n",
    "    encoder = LabelEncoder()\n",
    "    Y_encoded = encoder.fit_transform(Y)\n",
    "    print(\"Encoded labels\")\n",
    "    pca = PCA(n_components=30)\n",
    "    EMBEDDED_X = pca.fit_transform(EMBEDDED_X)\n",
    "    print(f\"PCA reduced dimensions to: {EMBEDDED_X.shape[1]}\")\n",
    "    print(f\"Explained variance ratio: {sum(pca.explained_variance_ratio_):.4f}\")\n",
    "    print(f\"PCA time: {time.time() - start_time:.2f} seconds\")\n",
    "    pca_cache = \"/Users/anantasingh/Desktop/advcslocal2/output/pca_transformed_full.npz\"\n",
    "    np.savez_compressed(pca_cache, EMBEDDED_X=EMBEDDED_X, Y_encoded=Y_encoded)\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        EMBEDDED_X, Y_encoded, test_size=0.2, random_state=42, stratify=Y_encoded\n",
    "    )\n",
    "    print(f\"Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
    "    print(f\"Data split time: {time.time() - start_time:.2f} seconds\")\n",
    "    gc.collect()\n",
    "    print(f\"Memory usage before training: {psutil.virtual_memory().percent}%\")\n",
    "\n",
    "    # class weights\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(Y_encoded), y=Y_encoded)\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "    # Train SVM\n",
    "    start_time = time.time()\n",
    "    print(\"Starting SVM training...\")\n",
    "    svm = SVC(probability=True, class_weight='balanced')\n",
    "    svm_param_grid = {\n",
    "        'C': [0.001, 0.01],\n",
    "        'kernel': ['rbf', 'linear'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "    svm_grid = GridSearchCV(svm, svm_param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "    svm_grid.fit(X_train, Y_train)\n",
    "    best_svm = svm_grid.best_estimator_\n",
    "    print(f\"Best SVM parameters: {svm_grid.best_params_}\")\n",
    "    svm_scores = cross_val_score(best_svm, X_train, Y_train, cv=5)\n",
    "    print(f\"SVM Cross-validation accuracy: {svm_scores.mean():.2f} ± {svm_scores.std():.2f}\")\n",
    "    svm_y_pred = best_svm.predict(X_test)\n",
    "    svm_test_accuracy = best_svm.score(X_test, Y_test)\n",
    "    print(f\"SVM Test accuracy: {svm_test_accuracy:.2f}\")\n",
    "    print(\"SVM Classification Report:\")\n",
    "    print(classification_report(Y_test, svm_y_pred, target_names=encoder.classes_))\n",
    "    y_test_bin = label_binarize(Y_test, classes=range(len(encoder.classes_)))\n",
    "    svm_y_score = best_svm.predict_proba(X_test)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    svm_eers = []\n",
    "    for i, name in enumerate(encoder.classes_):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test_bin[:, i], svm_y_score[:, i])\n",
    "        auc = roc_auc_score(y_test_bin[:, i], svm_y_score[:, i])\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.2f})')\n",
    "        fnr = 1 - tpr\n",
    "        eer_idx = np.nanargmin(np.abs(fpr - fnr))\n",
    "        eer = fpr[eer_idx]\n",
    "        svm_eers.append(eer)\n",
    "        print(f\"SVM EER for {name}: {eer:.4f}\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('SVM ROC Curves')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"/Users/anantasingh/Desktop/advcslocal2/output/svm_roc_curves.png\")\n",
    "    plt.close()\n",
    "    print(f\"SVM Average EER: {np.mean(svm_eers):.4f}\")\n",
    "    print(f\"SVM training and evaluation time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # Train MLP\n",
    "    start_time = time.time()\n",
    "    print(\"Starting MLP training...\")\n",
    "    mlp = MLPClassifier(max_iter=2000, random_state=42)\n",
    "    mlp_param_grid = {\n",
    "        'hidden_layer_sizes': [(100,), (100, 50)],\n",
    "        'learning_rate_init': [0.001, 0.01],\n",
    "        'alpha': [0.001, 0.01]\n",
    "    }\n",
    "    mlp_grid = GridSearchCV(mlp, mlp_param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "    mlp_grid.fit(X_train, Y_train)\n",
    "    best_mlp = mlp_grid.best_estimator_\n",
    "    print(f\"Best MLP parameters: {mlp_grid.best_params_}\")\n",
    "    mlp_scores = cross_val_score(best_mlp, X_train, Y_train, cv=5)\n",
    "    print(f\"MLP Cross-validation accuracy: {mlp_scores.mean():.2f} ± {mlp_scores.std():.2f}\")\n",
    "    mlp_y_pred = best_mlp.predict(X_test)\n",
    "    mlp_test_accuracy = best_mlp.score(X_test, Y_test)\n",
    "    print(f\"MLP Test accuracy: {mlp_test_accuracy:.2f}\")\n",
    "    print(\"MLP Classification Report:\")\n",
    "    print(classification_report(Y_test, mlp_y_pred, target_names=encoder.classes_))\n",
    "    mlp_y_score = best_mlp.predict_proba(X_test)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    mlp_eers = []\n",
    "    for i, name in enumerate(encoder.classes_):\n",
    "        fpr, tpr, _ = roc_curve(y_test_bin[:, i], mlp_y_score[:, i])\n",
    "        auc = roc_auc_score(y_test_bin[:, i], mlp_y_score[:, i])\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.2f})')\n",
    "        fnr = 1 - tpr\n",
    "        eer_idx = np.nanargmin(np.abs(fpr - fnr))\n",
    "        eer = fpr[eer_idx]\n",
    "        mlp_eers.append(eer)\n",
    "        print(f\"MLP EER for {name}: {eer:.4f}\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('MLP ROC Curves')\n",
    "    plt.legend()\n",
    "    plt.savefig('/Users/anantasingh/Desktop/advcslocal2/output/mlp_roc.png')\n",
    "    plt.close()\n",
    "    print(f\"MLP Average EER: {np.mean(mlp_eers):.4f}\")\n",
    "    print(f\"MLP training and evaluation time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # Trained Random Forest\n",
    "    start_time = time.time()\n",
    "    print(\"Starting Random Forest training...\")\n",
    "    rf = RandomForestClassifier(max_depth=8, min_samples_split=5, class_weight='balanced', random_state=42)\n",
    "    rf_param_grid = {'n_estimators': [100, 200]}\n",
    "    rf_grid = GridSearchCV(rf, rf_param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "    rf_grid.fit(X_train, Y_train)\n",
    "    best_rf = rf_grid.best_estimator_\n",
    "    print(f\"Best Random Forest parameters: {rf_grid.best_params_}\")\n",
    "    rf_scores = cross_val_score(best_rf, X_train, Y_train, cv=5)\n",
    "    print(f\"Random Forest Cross-validation accuracy: {rf_scores.mean():.2f} ± {rf_scores.std():.2f}\")\n",
    "    rf_y_pred = best_rf.predict(X_test)\n",
    "    rf_test_accuracy = best_rf.score(X_test, Y_test)\n",
    "    print(f\"Random Forest Test accuracy: {rf_test_accuracy:.2f}\")\n",
    "    print(\"Random Forest Classification Report:\")\n",
    "    print(classification_report(Y_test, rf_y_pred, target_names=encoder.classes_))\n",
    "    rf_y_score = best_rf.predict_proba(X_test)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    rf_eers = []\n",
    "    for i, name in enumerate(encoder.classes_):\n",
    "        fpr, tpr, _ = roc_curve(y_test_bin[:, i], rf_y_score[:, i])\n",
    "        auc = roc_auc_score(y_test_bin[:, i], rf_y_score[:, i])\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.2f})')\n",
    "        fnr = 1 - tpr\n",
    "        eer_idx = np.nanargmin(np.abs(fpr - fnr))\n",
    "        eer = fpr[eer_idx]\n",
    "        rf_eers.append(eer)\n",
    "        print(f\"Random Forest EER for {name}: {eer:.4f}\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Random Forest ROC Curves')\n",
    "    plt.legend()\n",
    "    plt.savefig('/Users/anantasingh/Desktop/advcslocal2/output/rf_roc.png')\n",
    "    plt.close()\n",
    "    print(f\"Random Forest Average EER: {np.mean(rf_eers):.4f}\")\n",
    "    print(f\"Random Forest training and evaluation time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # Save models\n",
    "    model_path = \"/Users/anantasingh/Desktop/advcslocal2/output/face_models_full.pkl\"\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'svm': best_svm,\n",
    "            'mlp': best_mlp,\n",
    "            'rf': best_rf,\n",
    "            'pca': pca,\n",
    "            'scaler': scaler,\n",
    "            'encoder': encoder\n",
    "        }, f)\n",
    "    print(f\"Models saved to {model_path}\")\n",
    "\n",
    "    # PCA variance\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Cumulative Explained Variance')\n",
    "    plt.title('PCA Explained Variance')\n",
    "    plt.savefig('/Users/anantasingh/Desktop/advcslocal2/output/pca_variance.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Confusion Matrices\n",
    "    for name, y_pred, path in [\n",
    "        ('SVM', svm_y_pred, '/Users/anantasingh/Desktop/advcslocal2/output/svm_cm.png'),\n",
    "        ('MLP', mlp_y_pred, '/Users/anantasingh/Desktop/advcslocal2/output/mlp_cm.png'),\n",
    "        ('Random Forest', rf_y_pred, '/Users/anantasingh/Desktop/advcslocal2/output/rf_cm.png')\n",
    "    ]:\n",
    "        cm = confusion_matrix(Y_test, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.title(f'{name} Confusion Matrix')\n",
    "        plt.savefig(path)\n",
    "        plt.close()\n",
    "\n",
    "    # t-SNE Visualization\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    X_tsne = tsne.fit_transform(EMBEDDED_X[:1000])\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for cls in np.unique(Y_encoded):\n",
    "        idx = Y_encoded[:1000] == cls\n",
    "        plt.scatter(X_tsne[idx, 0], X_tsne[idx, 1], label=encoder.classes_[cls], alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.title('t-SNE Visualization of Embeddings')\n",
    "    plt.savefig('/Users/anantasingh/Desktop/advcslocal2/output/tsne.png')\n",
    "    plt.close()\n",
    "\n",
    "    # # Embedding Similarity Check\n",
    "    # from sklearn.metrics.pairwise import cosine_similarity\n",
    "    # sim_matrix = cosine_similarity(EMBEDDED_X[:1000])\n",
    "    # intra_class_sim = []\n",
    "    # inter_class_sim = []\n",
    "    # for i in range(1000):\n",
    "    #     for j in range(i + 1, 1000):\n",
    "    #         if Y_encoded[i] == Y_encoded[j]:\n",
    "    #             intra_class_sim.append(sim_matrix[i, j])\n",
    "    #         else:\n",
    "    #             inter_class_sim.append(sim_matrix[i, j])\n",
    "    # print(f\"Intra-class similarity: mean={np.mean(intra_class_sim):.4f}, std={np.std(intra_class_sim):.4f}\")\n",
    "    # print(f\"Inter-class similarity: mean={np.mean(inter_class_sim):.4f}, std={np.std(inter_class_sim):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00488519-ea4f-410b-adce-0c030c1f1341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CoreMLExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CoreMLExecutionProvider': {}}\n",
      "find model: /Users/anantasingh/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CoreMLExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CoreMLExecutionProvider': {}}\n",
      "find model: /Users/anantasingh/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CoreMLExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CoreMLExecutionProvider': {}}\n",
      "find model: /Users/anantasingh/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CoreMLExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CoreMLExecutionProvider': {}}\n",
      "find model: /Users/anantasingh/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CoreMLExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CoreMLExecutionProvider': {}}\n",
      "find model: /Users/anantasingh/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (320, 320)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CoreMLExecutionProvider, AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "inswapper-shape: [1, 3, 128, 128]\n",
      "Generating deepfakes for leo_lindsay_pair (Leonardo_DiCaprio and Lindsay_Lohan)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Leonardo_DiCaprio/73.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/186.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Lindsay_Lohan/leo_lindsay_pair_Leonardo_DiCaprio_swapped_with_Lindsay_Lohan_0.jpg\n",
      "Attempt 1: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/333.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Leonardo_DiCaprio/129.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Leonardo_DiCaprio/leo_lindsay_pair_Lindsay_Lohan_swapped_with_Leonardo_DiCaprio_1.jpg\n",
      "Attempt 2: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Leonardo_DiCaprio/123.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/122.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Lindsay_Lohan/leo_lindsay_pair_Leonardo_DiCaprio_swapped_with_Lindsay_Lohan_2.jpg\n",
      "Attempt 2: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/502.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Leonardo_DiCaprio/96.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Leonardo_DiCaprio/leo_lindsay_pair_Lindsay_Lohan_swapped_with_Leonardo_DiCaprio_3.jpg\n",
      "Attempt 3: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Leonardo_DiCaprio/67.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/191.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Lindsay_Lohan/leo_lindsay_pair_Leonardo_DiCaprio_swapped_with_Lindsay_Lohan_4.jpg\n",
      "Attempt 3: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/493.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Leonardo_DiCaprio/201.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Leonardo_DiCaprio/leo_lindsay_pair_Lindsay_Lohan_swapped_with_Leonardo_DiCaprio_5.jpg\n",
      "Attempt 4: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Leonardo_DiCaprio/243.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/237.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Lindsay_Lohan/leo_lindsay_pair_Leonardo_DiCaprio_swapped_with_Lindsay_Lohan_6.jpg\n",
      "Attempt 4: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/125.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Leonardo_DiCaprio/117.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Leonardo_DiCaprio/leo_lindsay_pair_Lindsay_Lohan_swapped_with_Leonardo_DiCaprio_7.jpg\n",
      "Attempt 5: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Leonardo_DiCaprio/67.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/219.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Lindsay_Lohan/leo_lindsay_pair_Leonardo_DiCaprio_swapped_with_Lindsay_Lohan_8.jpg\n",
      "Attempt 5: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/417.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Leonardo_DiCaprio/103.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Leonardo_DiCaprio/leo_lindsay_pair_Lindsay_Lohan_swapped_with_Leonardo_DiCaprio_9.jpg\n",
      "Attempt 6: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Leonardo_DiCaprio/100.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/117.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Lindsay_Lohan/leo_lindsay_pair_Leonardo_DiCaprio_swapped_with_Lindsay_Lohan_10.jpg\n",
      "Attempt 6: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/141.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Leonardo_DiCaprio/97.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Leonardo_DiCaprio/leo_lindsay_pair_Lindsay_Lohan_swapped_with_Leonardo_DiCaprio_11.jpg\n",
      "Attempt 7: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Leonardo_DiCaprio/8.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/392.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Lindsay_Lohan/leo_lindsay_pair_Leonardo_DiCaprio_swapped_with_Lindsay_Lohan_12.jpg\n",
      "Attempt 7: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/0.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Leonardo_DiCaprio/302.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Leonardo_DiCaprio/leo_lindsay_pair_Lindsay_Lohan_swapped_with_Leonardo_DiCaprio_13.jpg\n",
      "Attempt 8: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Leonardo_DiCaprio/136.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/412.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Lindsay_Lohan/leo_lindsay_pair_Leonardo_DiCaprio_swapped_with_Lindsay_Lohan_14.jpg\n",
      "Attempt 8: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/550.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Leonardo_DiCaprio/163.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Leonardo_DiCaprio/leo_lindsay_pair_Lindsay_Lohan_swapped_with_Leonardo_DiCaprio_15.jpg\n",
      "No faces detected in: /Users/anantasingh/Desktop/advcslocal2/celebrities/Leonardo_DiCaprio/104.jpg\n",
      "Attempt 9: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Leonardo_DiCaprio/60.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/357.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Lindsay_Lohan/leo_lindsay_pair_Leonardo_DiCaprio_swapped_with_Lindsay_Lohan_16.jpg\n",
      "Attempt 9: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/125.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Leonardo_DiCaprio/82.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Leonardo_DiCaprio/leo_lindsay_pair_Lindsay_Lohan_swapped_with_Leonardo_DiCaprio_17.jpg\n",
      "Attempt 10: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Leonardo_DiCaprio/11.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/263.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Lindsay_Lohan/leo_lindsay_pair_Leonardo_DiCaprio_swapped_with_Lindsay_Lohan_18.jpg\n",
      "Attempt 10: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Lindsay_Lohan/177.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Leonardo_DiCaprio/130.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Leonardo_DiCaprio/leo_lindsay_pair_Lindsay_Lohan_swapped_with_Leonardo_DiCaprio_19.jpg\n",
      "Generated 10 deepfakes for leo_lindsay_pair\n",
      "Generating deepfakes for orlando_tom_pair (Orlando_Bloom and Tom_Cruise)\n",
      "Attempt 1: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Orlando_Bloom/102.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Tom_Cruise/40.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Tom_Cruise/orlando_tom_pair_Orlando_Bloom_swapped_with_Tom_Cruise_0.jpg\n",
      "Attempt 1: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Tom_Cruise/86.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Orlando_Bloom/112.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Orlando_Bloom/orlando_tom_pair_Tom_Cruise_swapped_with_Orlando_Bloom_1.jpg\n",
      "Attempt 2: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Orlando_Bloom/292.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Tom_Cruise/61.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Tom_Cruise/orlando_tom_pair_Orlando_Bloom_swapped_with_Tom_Cruise_2.jpg\n",
      "Attempt 2: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Tom_Cruise/17.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Orlando_Bloom/540.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Orlando_Bloom/orlando_tom_pair_Tom_Cruise_swapped_with_Orlando_Bloom_3.jpg\n",
      "Attempt 3: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Orlando_Bloom/488.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Tom_Cruise/15.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Tom_Cruise/orlando_tom_pair_Orlando_Bloom_swapped_with_Tom_Cruise_4.jpg\n",
      "Attempt 3: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Tom_Cruise/185.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Orlando_Bloom/661.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Orlando_Bloom/orlando_tom_pair_Tom_Cruise_swapped_with_Orlando_Bloom_5.jpg\n",
      "Attempt 4: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Orlando_Bloom/easy_pair_141_swapped_with_2.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Tom_Cruise/153.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Tom_Cruise/orlando_tom_pair_Orlando_Bloom_swapped_with_Tom_Cruise_6.jpg\n",
      "Attempt 4: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Tom_Cruise/190.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Orlando_Bloom/193.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Orlando_Bloom/orlando_tom_pair_Tom_Cruise_swapped_with_Orlando_Bloom_7.jpg\n",
      "Attempt 5: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Orlando_Bloom/144.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Tom_Cruise/27.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Tom_Cruise/orlando_tom_pair_Orlando_Bloom_swapped_with_Tom_Cruise_8.jpg\n",
      "Attempt 5: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Tom_Cruise/169.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Orlando_Bloom/653.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Orlando_Bloom/orlando_tom_pair_Tom_Cruise_swapped_with_Orlando_Bloom_9.jpg\n",
      "Attempt 6: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Orlando_Bloom/112.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Tom_Cruise/54.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Tom_Cruise/orlando_tom_pair_Orlando_Bloom_swapped_with_Tom_Cruise_10.jpg\n",
      "Attempt 6: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Tom_Cruise/160.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Orlando_Bloom/easy_pair_8_swapped_with_111.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Orlando_Bloom/orlando_tom_pair_Tom_Cruise_swapped_with_Orlando_Bloom_11.jpg\n",
      "Attempt 7: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Orlando_Bloom/249.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Tom_Cruise/24.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Tom_Cruise/orlando_tom_pair_Orlando_Bloom_swapped_with_Tom_Cruise_12.jpg\n",
      "Attempt 7: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Tom_Cruise/challenging_pair_67_swapped_with_36.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Orlando_Bloom/87.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Orlando_Bloom/orlando_tom_pair_Tom_Cruise_swapped_with_Orlando_Bloom_13.jpg\n",
      "Attempt 8: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Orlando_Bloom/314.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Tom_Cruise/148.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Tom_Cruise/orlando_tom_pair_Orlando_Bloom_swapped_with_Tom_Cruise_14.jpg\n",
      "Attempt 8: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Tom_Cruise/challenging_pair_Lindsay_Lohan_swapped_with_Tom_Cruise.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Orlando_Bloom/198.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Orlando_Bloom/orlando_tom_pair_Tom_Cruise_swapped_with_Orlando_Bloom_15.jpg\n",
      "Attempt 9: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Orlando_Bloom/156.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Tom_Cruise/61.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Tom_Cruise/orlando_tom_pair_Orlando_Bloom_swapped_with_Tom_Cruise_16.jpg\n",
      "Attempt 9: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Tom_Cruise/158.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Orlando_Bloom/130.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Orlando_Bloom/orlando_tom_pair_Tom_Cruise_swapped_with_Orlando_Bloom_17.jpg\n",
      "Attempt 10: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Orlando_Bloom/259.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Tom_Cruise/135.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Tom_Cruise/orlando_tom_pair_Orlando_Bloom_swapped_with_Tom_Cruise_18.jpg\n",
      "Attempt 10: Generating deepfake for /Users/anantasingh/Desktop/advcslocal2/celebrities/Tom_Cruise/180.jpg -> /Users/anantasingh/Desktop/advcslocal2/celebrities/Orlando_Bloom/501.jpg\n",
      "Saved deepfake: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Orlando_Bloom/orlando_tom_pair_Tom_Cruise_swapped_with_Orlando_Bloom_19.jpg\n",
      "Generated 10 deepfakes for orlando_tom_pair\n"
     ]
    }
   ],
   "source": [
    "#Deepfake Generation InsightFace\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# Directory for PubFig dataset\n",
    "pubfig_dir = \"/Users/anantasingh/Desktop/advcslocal2/celebrities\"\n",
    "insightface_output_dir = \"/Users/anantasingh/Desktop/advcslocal2/output/deepfakes\"\n",
    "\n",
    "# Initialized InsightFace with CoreML for Metal GPU support, fallback to CPU\n",
    "app = FaceAnalysis(name='buffalo_l', providers=['CoreMLExecutionProvider', 'CPUExecutionProvider'])\n",
    "app.prepare(ctx_id=-1, det_size=(320, 320), det_thresh=0.3)  # ctx_id=-1 for GPU (CoreML/Metal)\n",
    "swapper = insightface.model_zoo.get_model('/Users/anantasingh/Desktop/advcslocal2/models/inswapper_128.onnx', download=False)\n",
    "\n",
    "# Function to get a valid image with detected face\n",
    "def get_valid_image(celeb_dir, max_attempts=10):\n",
    "    files = [f for f in os.listdir(celeb_dir) if f.endswith('.jpg')]\n",
    "    random.shuffle(files)\n",
    "    for i, filename in enumerate(files[:max_attempts]):\n",
    "        img_path = os.path.join(celeb_dir, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Failed to load: {img_path}\")\n",
    "            continue\n",
    "        faces = app.get(img)\n",
    "        if len(faces) > 0:\n",
    "            return img_path, img, faces[0]\n",
    "        print(f\"No faces detected in: {img_path}\")\n",
    "    print(f\"Failed to find a valid image with a face in {celeb_dir} after {max_attempts} attempts\")\n",
    "    return None, None, None\n",
    "\n",
    "# Generates a single deepfake\n",
    "def generate_insightface_deepfake(real_img, real_face, target_img, target_face, output_dir, real_name, target_name, pair_name, counter):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    real_ = real_img.copy()\n",
    "    # Generate and save the deepfake with real celebrity's face on target body\n",
    "    real_ = swapper.get(real_, real_face, target_face, paste_back=True)\n",
    "    real_celeb_name = os.path.basename(os.path.dirname(real_name))\n",
    "    target_celeb_name = os.path.basename(os.path.dirname(target_name))\n",
    "    swapped_real_path = os.path.join(output_dir, f\"{pair_name}_{real_celeb_name}_swapped_with_{target_celeb_name}_{counter}.jpg\")\n",
    "    cv2.imwrite(swapped_real_path, real_)\n",
    "    print(f\"Saved deepfake: {swapped_real_path}\")\n",
    "\n",
    "# Generates multiple deepfakes for a pair\n",
    "def generate_multiple_deepfakes(celeb1_dir, celeb2_dir, output_dir, pair_name, num_deepfakes=10):\n",
    "    celeb1_name = os.path.basename(celeb1_dir)\n",
    "    celeb2_name = os.path.basename(celeb2_dir)\n",
    "    celeb1_output_dir = os.path.join(output_dir, celeb1_name)\n",
    "    celeb2_output_dir = os.path.join(output_dir, celeb2_name)\n",
    "    os.makedirs(celeb1_output_dir, exist_ok=True)\n",
    "    os.makedirs(celeb2_output_dir, exist_ok=True)\n",
    "    successful_deepfakes = 0\n",
    "    attempts = 0\n",
    "    max_attempts = num_deepfakes * 2  # Allow extra attempts\n",
    "    counter = 0  # Unique counter for filenames\n",
    "    while successful_deepfakes < num_deepfakes and attempts < max_attempts:\n",
    "        real_path1, real_img1, real_face1 = get_valid_image(celeb1_dir)\n",
    "        target_path2, target_img2, target_face2 = get_valid_image(celeb2_dir)\n",
    "        real_path2, real_img2, real_face2 = get_valid_image(celeb2_dir)\n",
    "        target_path1, target_img1, target_face1 = get_valid_image(celeb1_dir)\n",
    "        if (real_img1 is None or target_img2 is None or real_img2 is None or target_img1 is None):\n",
    "            print(f\"Attempt {attempts + 1}: Skipping due to invalid images for {pair_name}\")\n",
    "            attempts += 1\n",
    "            continue\n",
    "        print(f\"Attempt {attempts + 1}: Generating deepfake for {real_path1} -> {target_path2}\")\n",
    "        generate_insightface_deepfake(\n",
    "            real_img1, real_face1, target_img2, target_face2,\n",
    "            celeb2_output_dir, real_path1, target_path2, pair_name, counter\n",
    "        )\n",
    "        counter += 1\n",
    "        print(f\"Attempt {attempts + 1}: Generating deepfake for {real_path2} -> {target_path1}\")\n",
    "        generate_insightface_deepfake(\n",
    "            real_img2, real_face2, target_img1, target_face1,\n",
    "            celeb1_output_dir, real_path2, target_path1, pair_name, counter\n",
    "        )\n",
    "        counter += 1\n",
    "        successful_deepfakes += 1\n",
    "        attempts += 1\n",
    "    print(f\"Generated {successful_deepfakes} deepfakes for {pair_name}\")\n",
    "\n",
    "# Define all desired pairs\n",
    "pairs = [\n",
    "    (\"Leonardo_DiCaprio\", \"Lindsay_Lohan\", \"leo_lindsay_pair\"),\n",
    "    (\"Orlando_Bloom\", \"Tom_Cruise\", \"orlando_tom_pair\")\n",
    "]\n",
    "\n",
    "# Generates deepfakes for all pairs\n",
    "for celeb1_name, celeb2_name, pair_name in pairs:\n",
    "    celeb1_dir = os.path.join(pubfig_dir, celeb1_name)\n",
    "    celeb2_dir = os.path.join(pubfig_dir, celeb2_name)\n",
    "    if os.path.isdir(celeb1_dir) and os.path.isdir(celeb2_dir):\n",
    "        print(f\"Generating deepfakes for {pair_name} ({celeb1_name} and {celeb2_name})\")\n",
    "        generate_multiple_deepfakes(celeb1_dir, celeb2_dir, insightface_output_dir, pair_name, num_deepfakes=10)\n",
    "    else:\n",
    "        print(f\"Directory not found for {celeb1_name} or {celeb2_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46329c41-3234-46f4-83a8-69ae35cfe594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/anantasingh/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/anantasingh/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/anantasingh/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/anantasingh/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/anantasingh/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (320, 320)\n",
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Lindsay_Lohan/leo_lindsay_pair_Leonardo_DiCaprio_swapped_with_Lindsay_Lohan_8.jpg | True: Lindsay_Lohan | Predicted: Lindsay_Lohan | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Lindsay_Lohan/leo_lindsay_pair_Leonardo_DiCaprio_swapped_with_Lindsay_Lohan_18.jpg | True: Lindsay_Lohan | Predicted: Lindsay_Lohan | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Lindsay_Lohan/leo_lindsay_pair_Leonardo_DiCaprio_swapped_with_Lindsay_Lohan_6.jpg | True: Lindsay_Lohan | Predicted: Lindsay_Lohan | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Lindsay_Lohan/leo_lindsay_pair_Leonardo_DiCaprio_swapped_with_Lindsay_Lohan_14.jpg | True: Lindsay_Lohan | Predicted: Lindsay_Lohan | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Lindsay_Lohan/leo_lindsay_pair_Leonardo_DiCaprio_swapped_with_Lindsay_Lohan_16.jpg | True: Lindsay_Lohan | Predicted: Lindsay_Lohan | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Lindsay_Lohan/leo_lindsay_pair_Leonardo_DiCaprio_swapped_with_Lindsay_Lohan_4.jpg | True: Lindsay_Lohan | Predicted: Lindsay_Lohan | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Lindsay_Lohan/leo_lindsay_pair_Leonardo_DiCaprio_swapped_with_Lindsay_Lohan_0.jpg | True: Lindsay_Lohan | Predicted: Lindsay_Lohan | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Lindsay_Lohan/leo_lindsay_pair_Leonardo_DiCaprio_swapped_with_Lindsay_Lohan_12.jpg | True: Lindsay_Lohan | Predicted: Lindsay_Lohan | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Lindsay_Lohan/leo_lindsay_pair_Leonardo_DiCaprio_swapped_with_Lindsay_Lohan_10.jpg | True: Lindsay_Lohan | Predicted: Lindsay_Lohan | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Lindsay_Lohan/leo_lindsay_pair_Leonardo_DiCaprio_swapped_with_Lindsay_Lohan_2.jpg | True: Lindsay_Lohan | Predicted: Lindsay_Lohan | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Tom_Cruise/orlando_tom_pair_Orlando_Bloom_swapped_with_Tom_Cruise_8.jpg | True: Tom_Cruise | Predicted: Tom_Cruise | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Tom_Cruise/orlando_tom_pair_Orlando_Bloom_swapped_with_Tom_Cruise_18.jpg | True: Tom_Cruise | Predicted: Tom_Cruise | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Tom_Cruise/orlando_tom_pair_Orlando_Bloom_swapped_with_Tom_Cruise_14.jpg | True: Tom_Cruise | Predicted: Tom_Cruise | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Tom_Cruise/orlando_tom_pair_Orlando_Bloom_swapped_with_Tom_Cruise_6.jpg | True: Tom_Cruise | Predicted: Tom_Cruise | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Tom_Cruise/orlando_tom_pair_Orlando_Bloom_swapped_with_Tom_Cruise_4.jpg | True: Tom_Cruise | Predicted: Tom_Cruise | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Tom_Cruise/orlando_tom_pair_Orlando_Bloom_swapped_with_Tom_Cruise_16.jpg | True: Tom_Cruise | Predicted: Tom_Cruise | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Tom_Cruise/orlando_tom_pair_Orlando_Bloom_swapped_with_Tom_Cruise_12.jpg | True: Tom_Cruise | Predicted: Tom_Cruise | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Tom_Cruise/orlando_tom_pair_Orlando_Bloom_swapped_with_Tom_Cruise_0.jpg | True: Tom_Cruise | Predicted: Tom_Cruise | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Tom_Cruise/orlando_tom_pair_Orlando_Bloom_swapped_with_Tom_Cruise_2.jpg | True: Tom_Cruise | Predicted: Tom_Cruise | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Tom_Cruise/orlando_tom_pair_Orlando_Bloom_swapped_with_Tom_Cruise_10.jpg | True: Tom_Cruise | Predicted: Tom_Cruise | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Leonardo_DiCaprio/leo_lindsay_pair_Lindsay_Lohan_swapped_with_Leonardo_DiCaprio_1.jpg | True: Leonardo_DiCaprio | Predicted: Leonardo_DiCaprio | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Leonardo_DiCaprio/leo_lindsay_pair_Lindsay_Lohan_swapped_with_Leonardo_DiCaprio_15.jpg | True: Leonardo_DiCaprio | Predicted: Leonardo_DiCaprio | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Leonardo_DiCaprio/leo_lindsay_pair_Lindsay_Lohan_swapped_with_Leonardo_DiCaprio_17.jpg | True: Leonardo_DiCaprio | Predicted: Leonardo_DiCaprio | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Leonardo_DiCaprio/leo_lindsay_pair_Lindsay_Lohan_swapped_with_Leonardo_DiCaprio_3.jpg | True: Leonardo_DiCaprio | Predicted: Leonardo_DiCaprio | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Leonardo_DiCaprio/leo_lindsay_pair_Lindsay_Lohan_swapped_with_Leonardo_DiCaprio_7.jpg | True: Leonardo_DiCaprio | Predicted: Leonardo_DiCaprio | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Leonardo_DiCaprio/leo_lindsay_pair_Lindsay_Lohan_swapped_with_Leonardo_DiCaprio_13.jpg | True: Leonardo_DiCaprio | Predicted: Leonardo_DiCaprio | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Leonardo_DiCaprio/leo_lindsay_pair_Lindsay_Lohan_swapped_with_Leonardo_DiCaprio_11.jpg | True: Leonardo_DiCaprio | Predicted: Miley_Cyrus | Correct: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Leonardo_DiCaprio/leo_lindsay_pair_Lindsay_Lohan_swapped_with_Leonardo_DiCaprio_5.jpg | True: Leonardo_DiCaprio | Predicted: Leonardo_DiCaprio | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Leonardo_DiCaprio/leo_lindsay_pair_Lindsay_Lohan_swapped_with_Leonardo_DiCaprio_9.jpg | True: Leonardo_DiCaprio | Predicted: Leonardo_DiCaprio | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Leonardo_DiCaprio/leo_lindsay_pair_Lindsay_Lohan_swapped_with_Leonardo_DiCaprio_19.jpg | True: Leonardo_DiCaprio | Predicted: Leonardo_DiCaprio | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Orlando_Bloom/orlando_tom_pair_Tom_Cruise_swapped_with_Orlando_Bloom_7.jpg | True: Orlando_Bloom | Predicted: Orlando_Bloom | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Orlando_Bloom/orlando_tom_pair_Tom_Cruise_swapped_with_Orlando_Bloom_5.jpg | True: Orlando_Bloom | Predicted: Orlando_Bloom | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Orlando_Bloom/orlando_tom_pair_Tom_Cruise_swapped_with_Orlando_Bloom_19.jpg | True: Orlando_Bloom | Predicted: Orlando_Bloom | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Orlando_Bloom/orlando_tom_pair_Tom_Cruise_swapped_with_Orlando_Bloom_1.jpg | True: Orlando_Bloom | Predicted: Orlando_Bloom | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Orlando_Bloom/orlando_tom_pair_Tom_Cruise_swapped_with_Orlando_Bloom_3.jpg | True: Orlando_Bloom | Predicted: Orlando_Bloom | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Orlando_Bloom/orlando_tom_pair_Tom_Cruise_swapped_with_Orlando_Bloom_13.jpg | True: Orlando_Bloom | Predicted: Orlando_Bloom | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Orlando_Bloom/orlando_tom_pair_Tom_Cruise_swapped_with_Orlando_Bloom_11.jpg | True: Orlando_Bloom | Predicted: Orlando_Bloom | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Orlando_Bloom/orlando_tom_pair_Tom_Cruise_swapped_with_Orlando_Bloom_9.jpg | True: Orlando_Bloom | Predicted: Orlando_Bloom | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Orlando_Bloom/orlando_tom_pair_Tom_Cruise_swapped_with_Orlando_Bloom_15.jpg | True: Orlando_Bloom | Predicted: Orlando_Bloom | Correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /Users/anantasingh/Desktop/advcslocal2/output/deepfakes/Orlando_Bloom/orlando_tom_pair_Tom_Cruise_swapped_with_Orlando_Bloom_17.jpg | True: Orlando_Bloom | Predicted: Orlando_Bloom | Correct: True\n",
      "Total deepfake images tested: 40\n",
      "Correct predictions: 39\n",
      "Misidentification rate: 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:1188: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/gpu_metal/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:1188: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Testing Previously Trained Model with Generated Deepfakes SVM\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Loading the trained SVM model\n",
    "model_path = \"/Users/anantasingh/Desktop/advcslocal2/output/face_models_full.pkl\"\n",
    "with open(model_path, 'rb') as f:\n",
    "    models = pickle.load(f)\n",
    "svm = models['svm']\n",
    "pca = models['pca']\n",
    "scaler = models['scaler']\n",
    "encoder = models['encoder']\n",
    "\n",
    "# Function to extract face and predict\n",
    "def predict_face(image_path, app):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Failed to load: {image_path}\")\n",
    "        return None\n",
    "    faces = app.get(img)\n",
    "    if len(faces) == 0:\n",
    "        print(f\"No face detected in: {image_path}\")\n",
    "        return None\n",
    "    face = cv2.resize(img, (160, 160))  # Match FR input size\n",
    "    face = face.astype('float32') / 255.0\n",
    "    face_tensor = torch.from_numpy(face).permute(2, 0, 1).unsqueeze(0).to(torch.device('cpu'))\n",
    "    with torch.no_grad():\n",
    "        embedder = InceptionResnetV1(pretrained='vggface2', classify=False).eval().to(torch.device('cpu'))\n",
    "        embedding = embedder(face_tensor).cpu().numpy()\n",
    "    embedding = embedding / np.linalg.norm(embedding, axis=1, keepdims=True)\n",
    "    embedding = scaler.transform(embedding)\n",
    "    embedding = pca.transform(embedding)\n",
    "    prediction = svm.predict(embedding)\n",
    "    return encoder.inverse_transform(prediction)[0]\n",
    "\n",
    "# Initialized InsightFace for face detection in deepfakes\n",
    "app = FaceAnalysis(name='buffalo_l', providers=['CPUExecutionProvider'])\n",
    "app.prepare(ctx_id=-1, det_size=(320, 320), det_thresh=0.3)\n",
    "\n",
    "# Directory for deepfake images\n",
    "deepfake_dir = \"/Users/anantasingh/Desktop/advcslocal2/output/deepfakes\"\n",
    "\n",
    "# Test deepfake images\n",
    "results = []\n",
    "for celeb1 in os.listdir(deepfake_dir):\n",
    "    celeb1_dir = os.path.join(deepfake_dir, celeb1)\n",
    "    if os.path.isdir(celeb1_dir):\n",
    "        for celeb2 in os.listdir(celeb1_dir):\n",
    "            if os.path.isfile(os.path.join(celeb1_dir, celeb2)) and celeb2.endswith('.jpg'):\n",
    "                # true_label = celeb2.split('_swapped_with_')[1].split('.')[0]  # Extract target celeb name\n",
    "                true_label = celeb2.split('_swapped_with_')[1].split('.')[0]  # Get 'Lindsay_Lohan_0'\n",
    "                true_label = '_'.join(true_label.split('_')[:-1])  # Remove the counter, get 'Lindsay_Lohan'\n",
    "                predicted_label = predict_face(os.path.join(celeb1_dir, celeb2), app)\n",
    "                if predicted_label is not None:\n",
    "                    results.append({\n",
    "                        'image_path': os.path.join(celeb1_dir, celeb2),\n",
    "                        'true_label': true_label,\n",
    "                        'predicted_label': predicted_label,\n",
    "                        'correct': true_label == predicted_label\n",
    "                    })\n",
    "                    print(f\"Image: {os.path.join(celeb1_dir, celeb2)} | True: {true_label} | Predicted: {predicted_label} | Correct: {true_label == predicted_label}\")\n",
    "\n",
    "# Calculate metrics\n",
    "total_deepfakes = len(results)\n",
    "correct_predictions = sum(1 for r in results if r['correct'])\n",
    "misidentification_rate = 1 - (correct_predictions / total_deepfakes) if total_deepfakes > 0 else 0\n",
    "print(f\"Total deepfake images tested: {total_deepfakes}\")\n",
    "print(f\"Correct predictions: {correct_predictions}\")\n",
    "print(f\"Misidentification rate: {misidentification_rate:.2f}\")\n",
    "\n",
    "# Visualize results\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Confusion Matrix for deepfake misidentification\n",
    "true_labels = [r['true_label'] for r in results]\n",
    "pred_labels = [r['predicted_label'] for r in results]\n",
    "cm = confusion_matrix(true_labels, pred_labels, labels=encoder.classes_)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=encoder.classes_, yticklabels=encoder.classes_, cmap='Blues')\n",
    "plt.title('Deepfake Misidentification Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.savefig('/Users/anantasingh/Desktop/advcslocal2/output/deepfake_confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# Bar plot of misidentification rate per class\n",
    "misid_per_class = {}\n",
    "for label in encoder.classes_:\n",
    "    true_count = sum(1 for r in results if r['true_label'] == label)\n",
    "    incorrect_count = sum(1 for r in results if r['true_label'] == label and not r['correct'])\n",
    "    misid_per_class[label] = incorrect_count / true_count if true_count > 0 else 0\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(misid_per_class.keys(), misid_per_class.values())\n",
    "plt.title('Misidentification Rate per Class for Deepfakes')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Misidentification Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig('/Users/anantasingh/Desktop/advcslocal2/output/deepfake_misid_rate.png')\n",
    "plt.close()\n",
    "\n",
    "# ROC-like curve (approximated using misclassification)\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "y_test_bin = label_binarize([r['true_label'] for r in results], classes=encoder.classes_)\n",
    "y_score = label_binarize([r['predicted_label'] for r in results], classes=encoder.classes_)\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(len(encoder.classes_)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, label in enumerate(encoder.classes_):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'{label} (AUC = {roc_auc[i]:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title('ROC Curves for Deepfake Misidentification')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.savefig('/Users/anantasingh/Desktop/advcslocal2/output/deepfake_roc_curves.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f055d28-49b4-4277-a873-86d23265f49f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpu_metal]",
   "language": "python",
   "name": "conda-env-gpu_metal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
